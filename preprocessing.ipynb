{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "600774ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/shivraj-pg/DEPNECT/Without_Context_Coarse/justForFun.conllu\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8788c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = text.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82fecb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tविकसित\t_\tComp6_Start\t_\t_\t4\tTatpurusha\t4\t8\n",
      "2\tशत\t_\tComp6_Middle\t_\t_\t3\tBahuvrihi\t3\t8\n",
      "3\tपत्र\t_\tComp6_Middle\t_\t_\t4\tTatpurusha\t4\t8\n",
      "4\tवु\t_\tComp6_Middle\t_\t_\t6\tBahuvrihi\t6\t8\n",
      "5\tरक्त\t_\tComp6_Middle\t_\t_\t6\tTatpurusha\t6\t8\n",
      "6\tनेत्रः\t_\tComp6_End\t_\t_\t8\tComp_root\t8\t8\n",
      "7\tवु\t_\tCompNo\t_\t_\t8\tNo_rel\t8\t8\n",
      "8\tDUMMY\t_\tCompNo\t_\t_\t0\troot\t0\t0\n",
      "\n",
      "1\tतस्याम्च\t_\tCompNo\t_\t_\t9\tNo_rel\t9\t9\n",
      "2\tतीर\t_\tComp6_Start\t_\t_\t3\tBahuvrihi\t3\t9\n",
      "3\tआदि\t_\tComp6_Middle\t_\t_\t4\tBahuvrihi\t4\t9\n",
      "4\tरूप\t_\tComp6_Middle\t_\t_\t5\tTatpurusha\t5\t9\n",
      "5\tसंबन्धि\t_\tComp6_Middle\t_\t_\t6\tTatpurusha\t6\t9\n",
      "6\tस्मृति\t_\tComp6_Middle\t_\t_\t7\tTatpurusha\t7\t9\n",
      "7\tजनक\t_\tComp6_End\t_\t_\t9\tComp_root\t9\t9\n",
      "8\tत्वमपि\t_\tCompNo\t_\t_\t9\tNo_rel\t9\t9\n",
      "9\tDUMMY\t_\tCompNo\t_\t_\t0\troot\t0\t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence, end = \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eecaf067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90dd2668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WL: ['1\\tविकसित\\t_\\tComp6_Start\\t_\\t_\\t4\\tTatpurusha\\t4\\t8', '2\\tशत\\t_\\tComp6_Middle\\t_\\t_\\t3\\tBahuvrihi\\t3\\t8', '3\\tपत्र\\t_\\tComp6_Middle\\t_\\t_\\t4\\tTatpurusha\\t4\\t8', '4\\tवु\\t_\\tComp6_Middle\\t_\\t_\\t6\\tBahuvrihi\\t6\\t8', '5\\tरक्त\\t_\\tComp6_Middle\\t_\\t_\\t6\\tTatpurusha\\t6\\t8', '6\\tनेत्रः\\t_\\tComp6_End\\t_\\t_\\t8\\tComp_root\\t8\\t8', '7\\tवु\\t_\\tCompNo\\t_\\t_\\t8\\tNo_rel\\t8\\t8', '8\\tDUMMY\\t_\\tCompNo\\t_\\t_\\t0\\troot\\t0\\t0']\n",
      "WL: ['1\\tतस्याम्च\\t_\\tCompNo\\t_\\t_\\t9\\tNo_rel\\t9\\t9', '2\\tतीर\\t_\\tComp6_Start\\t_\\t_\\t3\\tBahuvrihi\\t3\\t9', '3\\tआदि\\t_\\tComp6_Middle\\t_\\t_\\t4\\tBahuvrihi\\t4\\t9', '4\\tरूप\\t_\\tComp6_Middle\\t_\\t_\\t5\\tTatpurusha\\t5\\t9', '5\\tसंबन्धि\\t_\\tComp6_Middle\\t_\\t_\\t6\\tTatpurusha\\t6\\t9', '6\\tस्मृति\\t_\\tComp6_Middle\\t_\\t_\\t7\\tTatpurusha\\t7\\t9', '7\\tजनक\\t_\\tComp6_End\\t_\\t_\\t9\\tComp_root\\t9\\t9', '8\\tत्वमपि\\t_\\tCompNo\\t_\\t_\\t9\\tNo_rel\\t9\\t9', '9\\tDUMMY\\t_\\tCompNo\\t_\\t_\\t0\\troot\\t0\\t0']\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    wordlines = sentence.split(\"\\n\")\n",
    "    print(\"WL:\",wordlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be13abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conllu_to_df(conllu_file_path):\n",
    "    with open(conllu_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    sentences = text.split(\"\\n\\n\")\n",
    "\n",
    "    for sentence in sentences:\n",
    "        wordlines = sentence.split(\"\\n\")\n",
    "\n",
    "    df_index = 0\n",
    "    df = pd.DataFrame(columns=[\"sentence\", \"sandhied-sent\", \"compound-info\"])\n",
    "    for sentence in sentences:\n",
    "        try:\n",
    "            # print(\"SENTENCE\\n\", sentence, end=\"\\n\\n\", sep=\"\")\n",
    "            wordlines = sentence.split(\"\\n\")\n",
    "            sandhi = []\n",
    "            output = []\n",
    "            for word in wordlines:\n",
    "                comp_data = word.split('\\t')\n",
    "                sandhi.append(comp_data[1])\n",
    "                output.append(\" \".join(\n",
    "                    [comp_data[0], comp_data[1], comp_data[3], comp_data[6], comp_data[7]]))\n",
    "\n",
    "            # print(\"word: \", \"\".join(sandhi).replace(\", DUMMY\", \"\").replace(\"DUMMY\",\"\"))\n",
    "            # print(\"Sandhi: \", \", \".join(sandhi))\n",
    "            # print(\"Output: \\n\", \"\\n\".join(output), sep=\"\")\n",
    "            # print(\"##############################################################################################\")\n",
    "\n",
    "            df.loc[df_index] = [\"\".join(sandhi).replace(\n",
    "                \", DUMMY\", \"\"), \", \".join(sandhi), \"\\n\".join(output)]\n",
    "            df_index = df_index + 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            with open(\"/home/shivraj-pg/DEPNECT/error.txt\", \"a\", encoding=\"utf-8\") as errorf:\n",
    "                x = conllu_file_path.replace(\".conllu\", \"\")\n",
    "                errorf.write(f\"{x} DATASET ADDITION ERROR: \\n\")\n",
    "                errorf.write(sentence)\n",
    "                errorf.write(\"#################################################################################################\\n\\n\")\n",
    "                errorf.close()\n",
    "                continue\n",
    "    f.close()    \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4b89e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sandhied-sent</th>\n",
       "      <th>compound-info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>विकसितशतपत्रवुरक्तनेत्रःवुDUMMY</td>\n",
       "      <td>विकसित, शत, पत्र, वु, रक्त, नेत्रः, वु, DUMMY</td>\n",
       "      <td>1 विकसित Comp6_Start 4 Tatpurusha\\n2 शत Comp6_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>तस्याम्चतीरआदिरूपसंबन्धिस्मृतिजनकत्वमपिDUMMY</td>\n",
       "      <td>तस्याम्च, तीर, आदि, रूप, संबन्धि, स्मृति, जनक,...</td>\n",
       "      <td>1 तस्याम्च CompNo 9 No_rel\\n2 तीर Comp6_Start ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence  \\\n",
       "0               विकसितशतपत्रवुरक्तनेत्रःवुDUMMY   \n",
       "1  तस्याम्चतीरआदिरूपसंबन्धिस्मृतिजनकत्वमपिDUMMY   \n",
       "\n",
       "                                       sandhied-sent  \\\n",
       "0      विकसित, शत, पत्र, वु, रक्त, नेत्रः, वु, DUMMY   \n",
       "1  तस्याम्च, तीर, आदि, रूप, संबन्धि, स्मृति, जनक,...   \n",
       "\n",
       "                                       compound-info  \n",
       "0  1 विकसित Comp6_Start 4 Tatpurusha\\n2 शत Comp6_...  \n",
       "1  1 तस्याम्च CompNo 9 No_rel\\n2 तीर Comp6_Start ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jff = conllu_to_df(\"/home/shivraj-pg/DEPNECT/Without_Context_Coarse/justForFun.conllu\")\n",
    "\n",
    "jff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6ec588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = conllu_to_df(\"/home/shivraj-pg/DEPNECT/Without_Context_Coarse/train.conllu\")\n",
    "test_df = conllu_to_df(\"/home/shivraj-pg/DEPNECT/Without_Context_Coarse/test.conllu\")\n",
    "\n",
    "train_df.to_csv(\"/home/shivraj-pg/DEPNECT/DATASETS/Train_withoutContext_coarse.csv\")\n",
    "test_df.to_csv(\"/home/shivraj-pg/DEPNECT/DATASETS/Test_withoutContext_coarse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dcdcb811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c55fbc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2940, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a272aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 स Comp2_Start 2 Bahuvrihi\\n2 सर्षपं Comp2_End 11 Comp_root\\n3 तुम्बुरु Comp3_Start 5 Dvandva\\n4 धान्य Comp3_Middle 5 Dvandva\\n5 वन्यं Comp3_End 11 Comp_root\\n6 चण्डां CompNo 11 No_rel\\n7 च CompNo 11 No_rel\\n8 चूर्णानि CompNo 11 No_rel\\n9 समानि CompNo 11 No_rel\\n10 कुर्यात् CompNo 11 No_rel\\n11 DUMMY CompNo 0 root'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['compound-info'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd79546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>{system}<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>Sanskrit text:{sentence}\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>Sandhi-Text: {sandhi}\n",
      "CompoundTypes:{compound_types}\n",
      "<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "TEMPLATE = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>{system}<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>Sanskrit text:{sentence}\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>Sandhi-Text: {sandhi}\\nCompoundTypes:{compound_types}\\n<|eot_id|>\"\"\"\n",
    "\n",
    "print(TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6abeae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged model saved to: /home/shivraj-pg/DEPNECT/OUT_finetuned_gemma3_4b_ft\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "BASE_MODEL = \"google/gemma-3-4b-it\"  # ⚠️ use the same model you fine-tuned\n",
    "ADAPTER_DIR = \"/home/shivraj-pg/DEPNECT/OUT_gemma4B_new/checkpoint-1000\"  # your adapter checkpoint\n",
    "OUTPUT_DIR = \"/home/shivraj-pg/DEPNECT/OUT_finetuned_gemma3_4b_ft\"\n",
    "\n",
    "# 1️⃣ Load base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# 2️⃣ Load adapter into the base model\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\n",
    "\n",
    "# 3️⃣ Merge adapter weights into base model\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "# 4️⃣ Save the merged final model\n",
    "merged_model.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "print(f\"Merged model saved to: {OUTPUT_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3143c3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/shivraj-pg/DEPNECT/OUT_finetuned_gemma3_4b_ft/tokenizer_config.json',\n",
       " '/home/shivraj-pg/DEPNECT/OUT_finetuned_gemma3_4b_ft/special_tokens_map.json',\n",
       " '/home/shivraj-pg/DEPNECT/OUT_finetuned_gemma3_4b_ft/chat_template.jinja',\n",
       " '/home/shivraj-pg/DEPNECT/OUT_finetuned_gemma3_4b_ft/tokenizer.model',\n",
       " '/home/shivraj-pg/DEPNECT/OUT_finetuned_gemma3_4b_ft/added_tokens.json',\n",
       " '/home/shivraj-pg/DEPNECT/OUT_finetuned_gemma3_4b_ft/tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab141137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depnect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
